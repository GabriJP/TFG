# EXPERIMENTACIÓN Y COMPARATIVA DE DIFERENTES MODELOS DE REDES NEURONALES ARTIFICIALES PARA EL PROCESAMIENTO DEL LENGUAJE NATURAL
## Trabajo de título del grado en ingeniería informática
### Julio de 2017

[![License: CC BY-NC-ND 4.0](https://img.shields.io/badge/License-CC%20BY--NC--ND%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc-nd/4.0/)


El procesamiento de lenguaje natural ha sido tradicionalmente una tarea compleja y poco trivial a la hora de diseñar algoritmos para su procesamiento. Gracias a la inteligencia artificial, se han conseguido grandes avances en este entorno y se han propuesto cada vez más modelos que hacen frente a los problemas normalmente poco tratables.

Este trabajo propone experimentar y comparar tres modelos de redes neuronales artificiales que han tenido bastante éxito en el procesamiento de lenguaje natural: LSTM (Long Short-Term Memory), MemN2N (modelo propuesto por Facebook) y DNC (modelo propuesto por Google). Para ello se han adaptado estos modelos optimizados a un ámbito concreto con el objetivo de comparar los resultados de cada uno.
